{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/michelucci/oreilly-london-ai/blob/master/day1/First_Example_of_a_CNN_(CIFAR10).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GIPHkImaoZzn"
   },
   "source": [
    "# First example of a CNN\n",
    "\n",
    "(C) Umberto Michelucci\n",
    "\n",
    "umberto.michelucci@toelt.ai\n",
    "\n",
    "www.toelt.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tkbZ5CjoZzu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.object = object   \n",
    "np.bool = bool   \n",
    "np.int = int  \n",
    "np.float = float    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use('classic')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oi9L4zskoZz4"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdVAo769oZ0G"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59.  62.  63.]\n",
      "   [ 43.  46.  45.]\n",
      "   [ 50.  48.  43.]\n",
      "   ...\n",
      "   [158. 132. 108.]\n",
      "   [152. 125. 102.]\n",
      "   [148. 124. 103.]]\n",
      "\n",
      "  [[ 16.  20.  20.]\n",
      "   [  0.   0.   0.]\n",
      "   [ 18.   8.   0.]\n",
      "   ...\n",
      "   [123.  88.  55.]\n",
      "   [119.  83.  50.]\n",
      "   [122.  87.  57.]]\n",
      "\n",
      "  [[ 25.  24.  21.]\n",
      "   [ 16.   7.   0.]\n",
      "   [ 49.  27.   8.]\n",
      "   ...\n",
      "   [118.  84.  50.]\n",
      "   [120.  84.  50.]\n",
      "   [109.  73.  42.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[208. 170.  96.]\n",
      "   [201. 153.  34.]\n",
      "   [198. 161.  26.]\n",
      "   ...\n",
      "   [160. 133.  70.]\n",
      "   [ 56.  31.   7.]\n",
      "   [ 53.  34.  20.]]\n",
      "\n",
      "  [[180. 139.  96.]\n",
      "   [173. 123.  42.]\n",
      "   [186. 144.  30.]\n",
      "   ...\n",
      "   [184. 148.  94.]\n",
      "   [ 97.  62.  34.]\n",
      "   [ 83.  53.  34.]]\n",
      "\n",
      "  [[177. 144. 116.]\n",
      "   [168. 129.  94.]\n",
      "   [179. 142.  87.]\n",
      "   ...\n",
      "   [216. 184. 140.]\n",
      "   [151. 118.  84.]\n",
      "   [123.  92.  72.]]]\n",
      "\n",
      "\n",
      " [[[154. 177. 187.]\n",
      "   [126. 137. 136.]\n",
      "   [105. 104.  95.]\n",
      "   ...\n",
      "   [ 91.  95.  71.]\n",
      "   [ 87.  90.  71.]\n",
      "   [ 79.  81.  70.]]\n",
      "\n",
      "  [[140. 160. 169.]\n",
      "   [145. 153. 154.]\n",
      "   [125. 125. 118.]\n",
      "   ...\n",
      "   [ 96.  99.  78.]\n",
      "   [ 77.  80.  62.]\n",
      "   [ 71.  73.  61.]]\n",
      "\n",
      "  [[140. 155. 164.]\n",
      "   [139. 146. 149.]\n",
      "   [115. 115. 112.]\n",
      "   ...\n",
      "   [ 79.  82.  64.]\n",
      "   [ 68.  70.  55.]\n",
      "   [ 67.  69.  55.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[175. 167. 166.]\n",
      "   [156. 154. 160.]\n",
      "   [154. 160. 170.]\n",
      "   ...\n",
      "   [ 42.  34.  36.]\n",
      "   [ 61.  53.  57.]\n",
      "   [ 93.  83.  91.]]\n",
      "\n",
      "  [[165. 154. 128.]\n",
      "   [156. 152. 130.]\n",
      "   [159. 161. 142.]\n",
      "   ...\n",
      "   [103.  93.  96.]\n",
      "   [123. 114. 120.]\n",
      "   [131. 121. 131.]]\n",
      "\n",
      "  [[163. 148. 120.]\n",
      "   [158. 148. 122.]\n",
      "   [163. 156. 133.]\n",
      "   ...\n",
      "   [143. 133. 139.]\n",
      "   [143. 134. 142.]\n",
      "   [143. 133. 144.]]]\n",
      "\n",
      "\n",
      " [[[255. 255. 255.]\n",
      "   [253. 253. 253.]\n",
      "   [253. 253. 253.]\n",
      "   ...\n",
      "   [253. 253. 253.]\n",
      "   [253. 253. 253.]\n",
      "   [253. 253. 253.]]\n",
      "\n",
      "  [[255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   ...\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]]\n",
      "\n",
      "  [[255. 255. 255.]\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   ...\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113. 120. 112.]\n",
      "   [111. 118. 111.]\n",
      "   [105. 112. 106.]\n",
      "   ...\n",
      "   [ 72.  81.  80.]\n",
      "   [ 72.  80.  79.]\n",
      "   [ 72.  80.  79.]]\n",
      "\n",
      "  [[111. 118. 110.]\n",
      "   [104. 111. 104.]\n",
      "   [ 99. 106.  98.]\n",
      "   ...\n",
      "   [ 68.  75.  73.]\n",
      "   [ 70.  76.  75.]\n",
      "   [ 78.  84.  82.]]\n",
      "\n",
      "  [[106. 113. 105.]\n",
      "   [ 99. 106.  98.]\n",
      "   [ 95. 102.  94.]\n",
      "   ...\n",
      "   [ 78.  85.  83.]\n",
      "   [ 79.  85.  83.]\n",
      "   [ 80.  86.  84.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 35. 178. 235.]\n",
      "   [ 40. 176. 239.]\n",
      "   [ 42. 176. 241.]\n",
      "   ...\n",
      "   [ 99. 177. 219.]\n",
      "   [ 79. 147. 197.]\n",
      "   [ 89. 148. 189.]]\n",
      "\n",
      "  [[ 57. 182. 234.]\n",
      "   [ 44. 184. 250.]\n",
      "   [ 50. 183. 240.]\n",
      "   ...\n",
      "   [156. 182. 200.]\n",
      "   [141. 177. 206.]\n",
      "   [116. 149. 175.]]\n",
      "\n",
      "  [[ 98. 197. 237.]\n",
      "   [ 64. 189. 252.]\n",
      "   [ 69. 192. 245.]\n",
      "   ...\n",
      "   [188. 195. 206.]\n",
      "   [119. 135. 147.]\n",
      "   [ 61.  79.  90.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 73.  79.  77.]\n",
      "   [ 53.  63.  68.]\n",
      "   [ 54.  68.  80.]\n",
      "   ...\n",
      "   [ 17.  40.  64.]\n",
      "   [ 21.  36.  51.]\n",
      "   [ 33.  48.  49.]]\n",
      "\n",
      "  [[ 61.  68.  75.]\n",
      "   [ 55.  70.  86.]\n",
      "   [ 57.  79. 103.]\n",
      "   ...\n",
      "   [ 24.  48.  72.]\n",
      "   [ 17.  35.  53.]\n",
      "   [  7.  23.  32.]]\n",
      "\n",
      "  [[ 44.  56.  73.]\n",
      "   [ 46.  66.  88.]\n",
      "   [ 49.  77. 105.]\n",
      "   ...\n",
      "   [ 27.  52.  77.]\n",
      "   [ 21.  43.  66.]\n",
      "   [ 12.  31.  50.]]]\n",
      "\n",
      "\n",
      " [[[189. 211. 240.]\n",
      "   [186. 208. 236.]\n",
      "   [185. 207. 235.]\n",
      "   ...\n",
      "   [175. 195. 224.]\n",
      "   [172. 194. 222.]\n",
      "   [169. 194. 220.]]\n",
      "\n",
      "  [[194. 210. 239.]\n",
      "   [191. 207. 236.]\n",
      "   [190. 206. 235.]\n",
      "   ...\n",
      "   [173. 192. 220.]\n",
      "   [171. 191. 218.]\n",
      "   [167. 190. 216.]]\n",
      "\n",
      "  [[208. 219. 244.]\n",
      "   [205. 216. 240.]\n",
      "   [204. 215. 239.]\n",
      "   ...\n",
      "   [175. 191. 217.]\n",
      "   [172. 190. 216.]\n",
      "   [169. 191. 215.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[207. 199. 181.]\n",
      "   [203. 195. 175.]\n",
      "   [203. 196. 173.]\n",
      "   ...\n",
      "   [135. 132. 127.]\n",
      "   [162. 158. 150.]\n",
      "   [168. 163. 151.]]\n",
      "\n",
      "  [[198. 190. 170.]\n",
      "   [189. 181. 159.]\n",
      "   [180. 172. 147.]\n",
      "   ...\n",
      "   [178. 171. 160.]\n",
      "   [175. 169. 156.]\n",
      "   [175. 169. 154.]]\n",
      "\n",
      "  [[198. 189. 173.]\n",
      "   [189. 181. 162.]\n",
      "   [178. 170. 149.]\n",
      "   ...\n",
      "   [195. 184. 169.]\n",
      "   [196. 189. 171.]\n",
      "   [195. 190. 171.]]]\n",
      "\n",
      "\n",
      " [[[229. 229. 239.]\n",
      "   [236. 237. 247.]\n",
      "   [234. 236. 247.]\n",
      "   ...\n",
      "   [217. 219. 233.]\n",
      "   [221. 223. 234.]\n",
      "   [222. 223. 233.]]\n",
      "\n",
      "  [[222. 221. 229.]\n",
      "   [239. 239. 249.]\n",
      "   [233. 234. 246.]\n",
      "   ...\n",
      "   [223. 223. 236.]\n",
      "   [227. 228. 238.]\n",
      "   [210. 211. 220.]]\n",
      "\n",
      "  [[213. 206. 211.]\n",
      "   [234. 232. 239.]\n",
      "   [231. 233. 244.]\n",
      "   ...\n",
      "   [220. 220. 232.]\n",
      "   [220. 219. 232.]\n",
      "   [202. 203. 215.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[150. 143. 135.]\n",
      "   [140. 135. 127.]\n",
      "   [132. 127. 120.]\n",
      "   ...\n",
      "   [224. 222. 218.]\n",
      "   [230. 228. 225.]\n",
      "   [241. 241. 238.]]\n",
      "\n",
      "  [[137. 132. 126.]\n",
      "   [130. 127. 120.]\n",
      "   [125. 121. 115.]\n",
      "   ...\n",
      "   [181. 180. 178.]\n",
      "   [202. 201. 198.]\n",
      "   [212. 211. 207.]]\n",
      "\n",
      "  [[122. 119. 114.]\n",
      "   [118. 116. 110.]\n",
      "   [120. 116. 111.]\n",
      "   ...\n",
      "   [179. 177. 173.]\n",
      "   [164. 164. 162.]\n",
      "   [163. 163. 161.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5-tlL69oZ0M"
   },
   "outputs": [],
   "source": [
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VhbpF0a5oZ0Q"
   },
   "outputs": [],
   "source": [
    "nClasses = 10\n",
    "y_train = utils.to_categorical(y_train,nClasses)\n",
    "y_test = utils.to_categorical(y_test,nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-Oih0Ud0oZ0U",
    "outputId": "c37841fc-5ea8-450b-a52d-0e1b2554137d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7HVNig-oZ0i"
   },
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTlsSHMboZ0o"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        9280      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 259,546\n",
      "Trainable params: 259,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5c2I8KOioZ0v"
   },
   "outputs": [],
   "source": [
    "AdamOpt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=AdamOpt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "WNE2vS46oZ06",
    "outputId": "e38bbd98-fd2f-49ba-baca-769e2b0465f9"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "dujpKQSjoZ1B",
    "outputId": "b7f15a83-38ce-4fed-da3d-115055a8d599"
   },
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "yHhL-PHHkuNh",
    "outputId": "7f90a0e0-b547-481f-b755-016865ddd4ab"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "3FV2D08UoZ1G",
    "outputId": "a8fb789b-ffb8-4eb9-9305-81da131b5df9"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "t0ETi-P4oZ1I",
    "outputId": "8d1589d6-4689-4c92-ef55-435979b9ffcb"
   },
   "outputs": [],
   "source": [
    "# Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'black',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'black',ls = '--', linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "#plt.title('Loss Curves',fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "Vsa4cwWopVBh",
    "outputId": "0adf5e9e-6524-4ff4-c274-a60251a444b6"
   },
   "outputs": [],
   "source": [
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['accuracy'],'black',linewidth=3.0)\n",
    "plt.plot(history.history['val_accuracy'],'black',ls = '--',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18, \n",
    "           loc = 'lower right')\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "#plt.title('Accuracy Curves',fontsize=16)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "First Example of a CNN (CIFAR10).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Py9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
