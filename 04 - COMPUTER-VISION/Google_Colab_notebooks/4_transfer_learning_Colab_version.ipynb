{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1z5mr4lG8yn9"
   },
   "source": [
    "# M3. Computer Vision (24.05.2024), Dr. Aygul Zagidullina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqNDta-xZ2u4"
   },
   "source": [
    "# Transfer Learning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp81GSFN7uHY"
   },
   "source": [
    "*  Tech companies and university labs have more computational resources than we do\n",
    "*  Let them train their very complex models on millions of images, and then re-use their kernels for our own CNNs!\n",
    "\n",
    "üéØ **<u>Goal:</u>**\n",
    "* ‚òÑÔ∏è Use a **Pretrained Neural Network** $ \\Leftrightarrow $ **Transfer learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR9-yIauZ2vA"
   },
   "source": [
    "## Google Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSm6iw9HizE"
   },
   "source": [
    "Repeat the same process from the last example to upload and open your notebook:\n",
    "\n",
    "1. access your [Google Drive](https://drive.google.com/)\n",
    "2. go into the Colab Notebooks folder\n",
    "3. drag and drop this notebook into it\n",
    "4. right-click the notebook file and select `Open with` $\\rightarrow$ `Google Colaboratory`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YfeVhhBZ2vC"
   },
   "source": [
    "Don't forget to enable GPU acceleration!\n",
    "\n",
    "`Runtime` $\\rightarrow$ `Change runtime type` $\\rightarrow$ `Hardware accelerator` $\\rightarrow$ `GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoRPmZtQZ2vE"
   },
   "source": [
    "When this is done, run the cells below and get to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsdd1Jv7Z2vJ"
   },
   "source": [
    "## (1) What is a Pre-Trained Neural Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shgjzVW4Z2vJ"
   },
   "source": [
    "* Convolutions are mathematical operations designed to detect specific patterns in input images and use them to classify the images.\n",
    "* One could imagine that these patterns are not 100% specific to one task but to the input images.\n",
    "\n",
    "üöÄ **Why not re-use these kernels - whose weights have already been optimized - somewhere else?**\n",
    "- The expectation is that the trained kernels could also help us perform another classification task.\n",
    "- We are trying to ***transfer*** the knowledge of a trained CNN to a new classification task.\n",
    "\n",
    "\n",
    "üí™ Transfer Learning has two main advantages:\n",
    "- It takes less time to train a pre-trained model since we are not going to update all the weights but only some of them\n",
    "- You benefit from state-of-the-art architectures that have been trained on complex images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOkQIQj4Z2vJ"
   },
   "source": [
    "## (2) Introduction to  VGG16\n",
    "\n",
    "üìö ***Reading Section, no code***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAkNOgtqF7S_"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this exercise, we will use the <a href=\"https://neurohive.io/en/popular-networks/vgg16/\">**`VGG-16 Neural Network`**</a>.\n",
    "\n",
    "> VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper ‚ÄúVery Deep Convolutional Networks for Large-Scale Image Recognition‚Äù. The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. It was one of the famous model submitted to ILSVRC-2014. It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3√ó3 kernel-sized filters one after another. VGG16 was trained for weeks and was using NVIDIA Titan Black GPU‚Äôs.\n",
    "\n",
    "VGG16 is a well-known architecture that has been trained on the <a href=\"https://www.image-net.org/\">**`ImageNet dataset`**</a> which is a very large database of images which belong to different categories.\n",
    "\n",
    "üëâ This architecture already learned which kernels are the best for extracting features from the images found in the `ImageNet dataset`.\n",
    "\n",
    "üëâ As we can see in the illustration, the VGG16 involves millions of parameters we don't want to retrain ourself.\n",
    "\n",
    "\n",
    "<center><img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\" width=400></center>\n",
    "\n",
    "‚ùì How does it work in practice ‚ùì\n",
    "\n",
    "* The first layers are not specialized for the particular task the VGG16 CNN was trained on\n",
    "* Only the last dense layer is a \"classification layers\" that can be preceded with a couple of dense layers...  Therefore, we will:\n",
    "    1. Load the existing VGG16 network\n",
    "    2. Remove the last fully connected layers\n",
    "    3. Replace them with some new fully-connected layers (whose weights are randomly set)\n",
    "    4. Train these last layers on a specific classification task.\n",
    "\n",
    "üòÉ Our role is to train only the last layers for our particular problem.\n",
    "\n",
    "ü§ì We will use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16\">**`tensorflow.keras.applications.VGG16`**</a>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-S858KRF7TA"
   },
   "source": [
    "## (3) Data loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzLvo4N5Z2vL"
   },
   "source": [
    "We have two options to load the data into Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6vPgeK2Z2vL"
   },
   "source": [
    "### (Option 1) Loading the data directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6FxEU-HZ2vL"
   },
   "source": [
    "* You can first get the data onto google Colab thanks to:\n",
    "\n",
    "`Files` $\\rightarrow$ `Upload to session storage`,\n",
    "\n",
    "* and then run\n",
    "\n",
    "`!unzip flowers-dataset.zip`\n",
    "\n",
    "*This is a very easy option to load the data into your working directory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID413NdhZ2vL"
   },
   "source": [
    "### (Option 2) Adding the data to Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsnMYzYgZ2vM"
   },
   "source": [
    "* You can first download the data from GitLab\n",
    "* You have to add it to your Google Drive in a folder called `transfer_learning_data` (for instance)\n",
    "* And run the following code in the notebook:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "```\n",
    "\n",
    "* The previous code will ask you to go to a given webpage where you can copy a temporary key\n",
    "* Paste it in the cell that will appear in your Colab Notebook\n",
    "* You can now load the data on your Google Colab Notebooks\n",
    "\n",
    "```python\n",
    "# Put Colab in the context of this exercise\n",
    "import os\n",
    "\n",
    "# os.chdir allows you to change directories, like cd in the Terminal\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/transfer_learning_data')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yrUUBluZ2vM"
   },
   "source": [
    "### Option 1 or Option 2 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdS5hErJF7TB"
   },
   "source": [
    "* Why choosing option 2 over the option 1?\n",
    "    * ‚úÖ The combo Colab + Drive can be interesting if you work within a project team, and need to update the data from time to time.\n",
    "    * ‚úÖ By doing this, you can share the same data folder with your teammates, and be sure that everyone has the same dataset at any time, even though someone changes it.\n",
    "    * ‚ùå Google Colab has now access to your Google Folder..., which you may or may not be in favor of, depending on your sensibilities...\n",
    "\n",
    "---\n",
    "\n",
    "‚ùì **Question: Loading your dataset** ‚ùì\n",
    "    \n",
    "Use one of the above methods to load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKw_1TjOF7TC"
   },
   "outputs": [],
   "source": [
    "option_1 = True # Choose here\n",
    "\n",
    "if option_1:\n",
    "    !unzip flowers-dataset.zip\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1716461863928,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "Zg9nA02c7zwZ",
    "outputId": "b3ef022f-6386-470a-d1a6-72d7768147f5"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1716461868509,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "PWHcf8wq7zwZ",
    "outputId": "5ff39317-c439-4047-c09f-1b18f0f94921"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onPwIzQzF7TE"
   },
   "source": [
    "‚ùì **Question:Train/Val/Test split** ‚ùì\n",
    "\n",
    "Use the following method to create\n",
    "`X_train, y_train, X_val, y_val, X_test, y_test, num_classes` depending on the `loading_method` you have used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "350Wx6vW7zwa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def load_flowers_data(loading_method):\n",
    "    if loading_method == 'colab':\n",
    "        data_path = '/content/drive/My Drive/transfer_learning_data/flowers'\n",
    "    elif loading_method == 'direct':\n",
    "        data_path = 'C:\\\\CASML\\\\cas-ml-fs-2025-GitHub\\\\04 - COMPUTER-VISION\\datasets\\\\flowers-dataset.zip\\\\flowers\\\\'\n",
    "    classes = {'daisy':0, 'dandelion':1, 'rose':2}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for (cl, i) in classes.items():\n",
    "        images_path = [elt for elt in os.listdir(os.path.join(data_path, cl)) if elt.find('.jpg')>0]\n",
    "        for img in tqdm(images_path[:300]):\n",
    "            path = os.path.join(data_path, cl, img)\n",
    "            if os.path.exists(path):\n",
    "                image = Image.open(path)\n",
    "                image = image.resize((256, 256))\n",
    "                imgs.append(np.array(image))\n",
    "                labels.append(i)\n",
    "\n",
    "    X = np.array(imgs)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    # Finally we shuffle:\n",
    "    p = np.random.permutation(len(X))\n",
    "    X, y = X[p], y[p]\n",
    "\n",
    "    first_split = int(len(imgs) /6.)\n",
    "    second_split = first_split + int(len(imgs) * 0.2)\n",
    "    X_test, X_val, X_train = X[:first_split], X[first_split:second_split], X[second_split:]\n",
    "    y_test, y_val, y_train = y[:first_split], y[first_split:second_split], y[second_split:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5237,
     "status": "ok",
     "timestamp": 1716462120669,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "hCeta8DQ7zwa",
    "outputId": "d1c787d1-3678-44ed-89f7-b738e6ff0330"
   },
   "outputs": [],
   "source": [
    "# CALL load_flowers_data WITH OUR PREFERRED METHOD HERE\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_classes = load_flowers_data('direct')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pm2IsMmGF7TH"
   },
   "source": [
    "‚ùì **Question: Exploring the images** ‚ùì\n",
    "\n",
    "Check the images' shapes and plot a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1716462123745,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "pRrXd-leF7TH",
    "outputId": "f2265c2a-94d5-40ec-aa29-becb98261019",
    "tags": [
     "delete_begin"
    ]
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1716462129333,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "b-sXtIQb7zwa",
    "outputId": "d5c119cc-c202-42f2-89a6-60d6ded24833"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 5100,
     "status": "ok",
     "timestamp": 1716462138441,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "2yWqaIy_F7TJ",
    "outputId": "13d1e09b-032a-4079-ce3f-50be7071c2ff",
    "tags": [
     "delete_end"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "for i in range(8):\n",
    "    plt.subplot(1,8,i+1)\n",
    "    plt.imshow(X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdMfP6dyF7TJ"
   },
   "source": [
    "## (4) A CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njYcWjw1F7TJ"
   },
   "source": [
    "First, let's build our own CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wneAeLYdF7TK"
   },
   "source": [
    "‚ùì **Questions** ‚ùì\n",
    "\n",
    "1. <u>CNN Architecture and compiler:</u> Create a CNN with our own architecture and a function `load_own_model` that will be able to generate it. Some advice:\n",
    "    - Incorporate the Rescaling Layer in our Sequential architecture\n",
    "    - Add three Conv2D/MaxPooling2D combinations with an increasing number of channels and a decreasing size of kernels for example (be creative, that is not a rule of thumb, mastering CNN is an art)\n",
    "    - Don't forget the Flatten layer and some hidden layers\n",
    "    - Finish with the predictive layer\n",
    "    - Compile our CNN model accordingly\n",
    "  \n",
    "  \n",
    "2. <u>Training and comparison</u>:\n",
    "    - Train our CNN\n",
    "    - Compare its performance to a baseline accuracy\n",
    "\n",
    "<details>\n",
    "    <summary><i>Recommended architecture:</i></summary>\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Notice this cool new layer that \"pipe\" your rescaling within the architecture\n",
    "model.add(Rescaling(1./255, input_shape=(256,256,3)))\n",
    "\n",
    "# Lets add 3 convolution layers, with relatively large kernel size as our pictures are quite big too\n",
    "model.add(layers.Conv2D(16, kernel_size=10, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "```\n",
    "\n",
    "        \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3B37zHeZ2vQ",
    "tags": [
     "delete_begin"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "def load_own_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Rescaling(1./255, input_shape=(256,256,3)))\n",
    "\n",
    "    model.add(layers.Conv2D(16, kernel_size=10, activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2287,
     "status": "ok",
     "timestamp": 1716462216765,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "MmaWuMtu7zwb",
    "outputId": "47b11875-e532-43f5-99e4-937ca3009886"
   },
   "outputs": [],
   "source": [
    "model_homemade = load_own_model()\n",
    "model_homemade.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21347,
     "status": "ok",
     "timestamp": 1716462242786,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "eLPDzQwt7zwc",
    "outputId": "06ca50fd-ac7b-4ce0-f929-390f709834fd"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_accuracy',\n",
    "                   mode = 'max',\n",
    "                   patience = 5,\n",
    "                   verbose = 1,\n",
    "                   restore_best_weights = True)\n",
    "\n",
    "history = model_homemade.fit(X_train, y_train,\n",
    "                             validation_data = (X_val, y_val),\n",
    "                             batch_size = 16,\n",
    "                             epochs = 100,\n",
    "                             callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53776,
     "status": "ok",
     "timestamp": 1716462367279,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "0SyXyrmjGkhR",
    "outputId": "ce1c5029-2aac-4511-ce16-aa8677acb592",
    "tags": [
     "delete_end"
    ]
   },
   "outputs": [],
   "source": [
    "res = model_homemade.evaluate(X_test, y_test)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1716463050628,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "xTkp8tG87zwc",
    "outputId": "e7c6d7a5-687e-4088-8a63-8a8f624c06df"
   },
   "outputs": [],
   "source": [
    "test_accuracy = res[-1]\n",
    "print(f\"test_accuracy = {round(test_accuracy,2)*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DC2SFwUZ2vR"
   },
   "source": [
    "ü•° <b><u>Takeaways from building our own CNN</u></b>:\n",
    "* On an \"easy dataset\" like the MNIST, it is now easy to reach a decent accuracy. But for a more complicated problem like classifying flowers, it already becomes more challenging. Let's take a few minutes to play with the following link before moving on to Transfer Learning\n",
    "    * [PoloClub/CNN-Explainer](https://poloclub.github.io/cnn-explainer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx8V9sny7cLP"
   },
   "source": [
    "## (5) Using a pre-trained CNN = Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxhI8bluZ2vR"
   },
   "source": [
    "As it's said in the beginning, tech companies and university labs have more computational resources than we do.\n",
    "\n",
    "üî• The [**Visual Geometry Group**](https://www.robots.ox.ac.uk/~vgg/data/) *(Oxford University, Department of Science and Engineering)* became famous for some of their **Very Deep Convolutional Neural Networks**: the [**VGG16**](https://www.robots.ox.ac.uk/~vgg/research/very_deep/)\n",
    "\n",
    "Take 7 minutes of your time to watch this incredible video of Convolutional Layers created by Dimitri Dmitriev.\n",
    "\n",
    "* üì∫ **[VGG16 Neural Network Visualization](https://www.youtube.com/watch?v=RNnKtNrsrmg)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZldqCInZ2vS"
   },
   "source": [
    "### (5.1) Load VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr6m5eKs9s54"
   },
   "source": [
    "‚ùì **Question: loading the VGG16** ‚ùì\n",
    "\n",
    "* Write a first function `load_model()` that loads the pretrained VGG-16 model from `tensorflow.keras.applications.vgg16`. Have a look at the documentation üìö  [tf/keras/applications/VGG16](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16)üìö\n",
    "\n",
    "* We will **load the VGG16 model** the following way:\n",
    "    - Let's use the **weights** learned on the [**imagenet dataset**](https://www.image-net.org/download.php) (14M pictures with 20k labels)\n",
    "    - The **`input_shape`** corresponds to the input shape of our images\n",
    "        - Note: *We have to resize them down to a consistent shape if they have different height/widths/channels*\n",
    "    - The **`include_top`** argument should be set to `False`:\n",
    "        - to avoid loading the weights of the fully-connected layers of the VGG16\n",
    "        - and also remove the last layer of the VGG16 which was specifically trained on `imagenet`\n",
    "\n",
    "<i><u>Remark:</u></i> Do not change the default value of the other arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCPwW3c37zwg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def load_model():\n",
    "\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape=X_train[0].shape)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3psG3JGF7TO"
   },
   "source": [
    "‚ùì **Question: number of parameters in the VGG16** ‚ùì\n",
    "\n",
    "Let's look at the architecture of the model using ***.summary()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4549,
     "status": "ok",
     "timestamp": 1716463121935,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "JtBpKLegF7TO",
    "outputId": "94d5defd-1010-4b23-b58c-3117bc83fa4f",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1IAwxRVF7TO"
   },
   "source": [
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\">\n",
    "\n",
    "Impressive, right? Two things to notice:\n",
    "- It ends with a combo Conv2D/MaxPooling2D\n",
    "- The `layers.Flatten` and the `layers.Dense` are not there yet, we need to add them.\n",
    "- There are more than 14,000,000 parameters, which is a lot...\n",
    "    - We could fine-tune them, i.e. update them as we will update the weights of the dense layers, but it will take a lot of time....\n",
    "    - For this reason, we will inform the model that the layers before the flattening will be set non-trainable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehMaUN34Z2vT"
   },
   "source": [
    "‚ùì **Question: deactivating the training of the VGG16 paramters** ‚ùì\n",
    "\n",
    "* Write a first function which:\n",
    "    - takes the previous model as the input\n",
    "    - sets the first layers to be non-trainable, by applying **`model.trainable = False`**\n",
    "    - returns the model.\n",
    "\n",
    "* Then inspect the summary of the model to check that the parameters are no longer trainable, they were set to be **`non-trainable`**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2d94FP57zwh"
   },
   "outputs": [],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "\n",
    "    # Set the first layers to be untrainable\n",
    "    model.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1716463187429,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "4_XYlwvJZ2vT",
    "outputId": "a57feff1-16a0-4e5e-a7e9-9a868ced80fc",
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "model = set_nontrainable_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4yedT2VF7TP"
   },
   "source": [
    "‚ùì **Question: chaining the pretrained convolutional layers of VGG16 with our own dense layers** ‚ùì\n",
    "\n",
    "We will write a function that adds flattening and dense layers after the convolutional layers. To do so, we cannot directly use the classic `layers.Sequential()` instantiation.\n",
    "\n",
    "For that reason, we will discover another way here. The idea is that we define each layer (or group of layers) separately. Then, we concatenate them. Let's look at this example:\n",
    "\n",
    "---\n",
    "```python\n",
    "base_model = load_model()\n",
    "base_model = set_nontrainable_layers(base_model)\n",
    "flattening_layer = layers.Flatten()\n",
    "dense_layer = layers.Dense(SOME_NUMBER_1, activation='relu')\n",
    "prediction_layer = layers.Dense(SOME_NUMBER_2, activation='APPROPRIATE_ACTIVATION')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  flattening_layer,\n",
    "  dense_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "* The first line loads a group of layers which is the previous VGG-16 model.\n",
    "* Then, we set these layers to be non-trainable.\n",
    "* Eventually, we can instantiate as many layers as we want.\n",
    "* Finally, we use the `Sequential` with the sequence of layers that will correspond to our overall neural network.\n",
    "\n",
    "Replicate the following steps by adding:\n",
    "* a flattening layer\n",
    "* two dense layers (the first with 500 neurons) to the previous VGG-16 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-85VZZ6e7zwh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n",
    "\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(500, activation='relu')\n",
    "    prediction_layer = layers.Dense(3, activation='softmax')\n",
    "\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-24j0psF7TQ"
   },
   "source": [
    "‚ùì **Question: inspect the parameters of a customized VGG16** ‚ùì\n",
    "\n",
    "* Now look at the layers and the parameters of our model.\n",
    "* Note that there is a distinction, at the end, between the **trainable** and **non-trainable parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1716463260490,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "0uqGuxsJF7TR",
    "outputId": "b6f169a4-ac1d-45d1-fe4b-60807f46882d",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "model = add_last_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxXlnPp5F7TR"
   },
   "source": [
    "‚ùì **Question: building a function that creates a full customized VGG16 and compiles it** ‚ùì\n",
    "\n",
    "* Write a function which builds and compiles our model\n",
    "    * We choose using the _adam_ optimizer with `learning_rate=1e-4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLO_yKqF7zwi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def build_model():\n",
    "\n",
    "    model = load_model()\n",
    "    model = add_last_layers(model)\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1560,
     "status": "ok",
     "timestamp": 1716463282310,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "O-XsFbyoZ2vU",
    "outputId": "d9dfd993-84dc-429e-f857-16f505b93e5f",
    "tags": [
     "delete"
    ]
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S96qsiKxZ2vU"
   },
   "source": [
    "### (5.2) Back to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbkwOw1eF7TS"
   },
   "source": [
    "üö® The VGG16 model was trained on images which were preprocessed in a specific way. This is the reason why we did _NOT_ normalize them earlier.\n",
    "\n",
    "‚ùì **Question: preprocessing the dataset** ‚ùì\n",
    "\n",
    "Apply the specific processing to the original (non-normalized) images here using the method **`preprocess_input`** that we can import from **`tensorflow.keras.applications.vgg16`**\n",
    "\n",
    "üìö Cf. [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4GwKD5a7zwi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNeJZvtV3YDf",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train = preprocess_input(X_train)\n",
    "X_val = preprocess_input(X_val)\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T7HvbQfZ2vZ"
   },
   "source": [
    "### (5.3)  Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu2H0KZF-EoI"
   },
   "source": [
    "\n",
    "\n",
    "‚ùì **Question: Training the customized VGG16** ‚ùì\n",
    "\n",
    "* Train the model with an Early stopping criterion on the validation accuracy\n",
    "* Since the validation data is provided, we use `validation_data` instead of `validation_split`.\n",
    "\n",
    "_As usual, we store the results of your training into a `history` variable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50238,
     "status": "ok",
     "timestamp": 1716463379290,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "grmnNmjeAXcQ",
    "outputId": "cb7e3503-85ab-4712-d1ec-a4e30e9248c0",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_accuracy',\n",
    "                   mode = 'max',\n",
    "                   patience = 5,\n",
    "                   verbose = 1,\n",
    "                   restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec_I9JpiAm-W"
   },
   "source": [
    "‚ùì **Question: Looking at the accuracy** ‚ùì\n",
    "\n",
    "Plot the accuracy for both the train set and and the validation set using the **plot_history** function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lF4OukOv7zwj"
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    #ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    #ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 1438,
     "status": "ok",
     "timestamp": 1716463523319,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "ESzinGOY6aBc",
    "outputId": "e7ab84d8-743c-4e79-9f4d-16a03f9888e3",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3plexlQAtcC"
   },
   "source": [
    "‚ùì **Question: Evaluating the model** ‚ùì\n",
    "\n",
    "Evaluate the customized VGG16 accuracy on the test set. Did we improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14366,
     "status": "ok",
     "timestamp": 1716463547112,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "ps_9HwUyRVj9",
    "outputId": "b0552ee8-7cfd-4e91-b4e0-b9d72e91a80f",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "res_vgg = model.evaluate(X_test, y_test)\n",
    "\n",
    "test_accuracy_vgg = res_vgg[-1]\n",
    "\n",
    "\n",
    "print(f\"test_accuracy_vgg = {round(test_accuracy_vgg,2)*100} %\")\n",
    "\n",
    "print(f\"test_accuracy = {round(test_accuracy,2)*100} %\")\n",
    "\n",
    "print(f'Chance level: {1./num_classes*100:.1f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5T1KvsGZ2va"
   },
   "source": [
    "## (6) (Optional) Improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF39HIb7BSOy"
   },
   "source": [
    "Now, we can try to improve the model's test accuracy. To do that, here are some options we can consider\n",
    "\n",
    "1. **Unfreeze and finetune**: Source: [Google tutorial](https://www.tensorflow.org/guide/keras/transfer_learning#fine-tuning)\n",
    ">_Once your model has converged on the new data, you can try to unfreeze all or part of the base model and retrain the whole model end-to-end with a very low learning rate. This is an optional last step that can potentially give you incremental improvements. It could also potentially lead to quick overfitting -- keep that in mind. It is critical to only do this step after the model with frozen layers has been trained to convergence. If you mix randomly-initialized trainable layers with trainable layers that hold pre-trained features, the randomly-initialized layers will cause very large gradient updates during training, which will destroy your pre-trained features. It's also critical to use a very low learning rate at this stage, because you are training a much larger model than in the first round of training, on a dataset that is typically very small. As a result, you are at risk of overfitting very quickly if you apply large weight updates. Here, you only want to readapt the pretrained weights in an incremental way._\n",
    "\n",
    "\n",
    "1. Add **Data Augmentation** if the model is overfitting.\n",
    "\n",
    "2. If our model is not overfitting, try a more complex model.\n",
    "\n",
    "3. Perform a precise **Grid Search** on all the hyper-parameters: learning_rate, batch_size, data augmentation etc...\n",
    "\n",
    "4. **Change the base model** to more modern CNN (ResNet, EfficientNet1,... available in the keras library)\n",
    "\n",
    "5. Curate the data: maintaining a sane data set is one of the keys to success.\n",
    "\n",
    "6. Collect more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5agNqtRQZ2va",
    "tags": [
     "delete_begin"
    ]
   },
   "source": [
    "## (6.1) Data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259218,
     "status": "ok",
     "timestamp": 1716463830836,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "2yMNPGjX7zwk",
    "outputId": "e28fd156-b486-4234-893b-30052b1b9140"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    brightness_range = (0.5, 1.),\n",
    "    zoom_range = (0.3, 1.5))\n",
    "\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "model_data_aug = build_model()\n",
    "\n",
    "train_flow = datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_flow = datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_accuracy',\n",
    "                   mode = 'max',\n",
    "                   patience = 5,\n",
    "                   verbose = 1,\n",
    "                   restore_best_weights = True)\n",
    "\n",
    "history_data_aug = model_data_aug.fit(train_flow,\n",
    "                                      validation_data = val_flow,\n",
    "                                      epochs = 50,\n",
    "                                      callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 1669,
     "status": "error",
     "timestamp": 1716463504256,
     "user": {
      "displayName": "Aygul Zagidullina",
      "userId": "13153899368049053995"
     },
     "user_tz": -120
    },
    "id": "n8qyLnNq7zwk",
    "outputId": "741fc907-82af-40f7-fe37-2d97fa588a06"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_data_aug.history['accuracy'])\n",
    "plt.plot(history_data_aug.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvsCub2JBre7",
    "outputId": "69a8006e-c901-47d1-c0b2-c8f99e5b04b3",
    "tags": [
     "delete_end"
    ]
   },
   "outputs": [],
   "source": [
    "res_aug = model_data_aug.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3UMNBZHZ2vb"
   },
   "source": [
    "## (6.2) Comparing the performances of the CNN, the VGG, and the VGG trained on the augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17lkqdeJ7zwl",
    "outputId": "1f737056-9d3d-4947-974f-229458fe4a21"
   },
   "outputs": [],
   "source": [
    "test_accuracy_aug = res_aug[-1]\n",
    "\n",
    "\n",
    "print(f\"test_accuracy_aug = {round(test_accuracy_aug,2)*100} %\")\n",
    "\n",
    "print(f\"test_accuracy_vgg = {round(test_accuracy_vgg,2)*100} %\")\n",
    "\n",
    "print(f\"test_accuracy = {round(test_accuracy,2)*100} %\")\n",
    "\n",
    "print(f'Chance level: {1./num_classes*100:.1f}%')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Py9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
