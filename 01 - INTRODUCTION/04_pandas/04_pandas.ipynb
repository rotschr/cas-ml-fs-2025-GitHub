{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c95e5de-e7f2-4997-a010-9d67ac44a6fc",
   "metadata": {},
   "source": [
    "# Working with Pandas\n",
    "\n",
    "Pandas has dataframes (df) and df are intuitively readable tables and that is very useful!\n",
    "\n",
    "In the notebook we will create Pandas DFs, learn methods to search the content, read CSV tables and apply simple transformations to the data. If you want to learn more about Pandas, have a look [here](https://www.w3schools.com/python/pandas/default.asp).\n",
    "\n",
    "The first step is to import Pandas. It should already be installed in Anaconda. If not, contact us or try a code cell with the following: `%pip install pandas` (only needs to be run once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bae6de-ba49-4e82-ae80-a7971a2f122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6bca70-0fa6-4fdc-b5ad-8dc5a28394a3",
   "metadata": {},
   "source": [
    "## Dataframe\n",
    "\n",
    "We create the first df “manually”, i.e. we first create a dictionary and then transfer it to Pandas.\n",
    "\n",
    "Using `print()` on a df does not look very good. We instead use `display()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b3f97-28cb-4cab-ab80-f38b0ceba35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dictionary\n",
    "data = {\"name\": [\"Otto\", \"Oskar\", \"Othmar\"],\n",
    "        \"groesse\": [181.3, 115.3, 153.4], \n",
    "        \"geburtstag\": [\"1983-07-18\", \"2019-09-21\", \"2017-03-01\"],\n",
    "        }\n",
    "\n",
    "#Dictionary to Pandas\n",
    "fam = pd.DataFrame(data=data)\n",
    "\n",
    "display(fam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815b37f-5059-4b8b-b52a-e05a54a05f1d",
   "metadata": {},
   "source": [
    "What column names are in the df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe62e8-3aa5-4c50-b5e8-d6ca18d0db41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284eb40-9512-4579-8daf-c6fe830ff458",
   "metadata": {},
   "source": [
    "What information can we find in the “name” column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a35199-ab17-4313-8047-919f2c1521c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e990e-99a5-40f6-af44-4fbfbe80baea",
   "metadata": {},
   "source": [
    "What data type does the “namen” column have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788a00e-2117-4bcc-b00f-fc73b8db08f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(fam[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75b080-ac1a-4100-b156-e091b5dbb7fe",
   "metadata": {},
   "source": [
    "Oops, that looks complicated. But we can also convert the Pandas series into a simple list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbd1f2-12e4-47a4-9a6e-091cab948366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam[\"name\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c6447-9db8-4050-967a-addeaaa78061",
   "metadata": {},
   "source": [
    "What is in the first (i.e. 0th) line of the data frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7435e3-9ab0-464e-80b8-8d1d56afd440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c35a5-bf30-4977-b929-52710dc00f73",
   "metadata": {
    "tags": []
   },
   "source": [
    "What is in the first two (0, 1) lines of the data frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f2859-7579-41e3-9c74-a7433dcd67c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0cca9-5598-443b-b4b2-d4fb0976bd5a",
   "metadata": {},
   "source": [
    "What is in the first two rows of the first column? (Python always indexes the rows first and then the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e4285-812a-4e04-ad3e-8bb58e160c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam.iloc[:2, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20ffaa-837f-4d5d-a2e9-45f4bb77880d",
   "metadata": {},
   "source": [
    "## CSV tables\n",
    "\n",
    "We don't actually want to create dfs ourselves, but rather read them from existing CSV tables, for example. This is what we do here. You have to choose the right `Seperator` and also the corresponding `Encoding` (character system -> otherwise the German Umlaute are wrong)\n",
    "\n",
    "By the way, the CSV is from [here](https://opendata.swiss/de/dataset/nachnamen-der-standigen-wohnbevolkerung-nach-kanton-1). It contains the frequency of surnames per canton. Physically, the CSV is in the same folder as the notebook (so we don't need to specify a path, just the name of the CSV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a310b-b0e4-4ebf-8cb1-904746ed4ec5",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5197e59e-9d9c-4b1c-9af3-befa302e1881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen = pd.read_csv(\"nachnamen.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "display(nachnamen.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb09a669-937d-42ed-83a7-1bddcb010b81",
   "metadata": {},
   "source": [
    "`info()` gives you a quick overview of all columns and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaba499-0b0a-4e74-885d-b86827756e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(nachnamen.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dac0c5",
   "metadata": {},
   "source": [
    "Data type `object` means that Python is either not sure (e.g. mixed data types in a column) or that the column is of type string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ee5a3-eac9-49e1-95ee-a46723186319",
   "metadata": {},
   "source": [
    "### Write CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e10848-9d34-466a-a355-194e8a1d638e",
   "metadata": {},
   "source": [
    "Because it was so easy to read, we write the Pandas table straight back into a CSV. We only select a few columns (using double brackets: `[[]]`) and the first 10 rows (`.head(10)`).\n",
    "\n",
    "`index=False` prevents Python from adding a first column that contains row numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c6444-fc46-47fc-bf80-f4fc9fe15f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen[[\"TIME_PERIOD\", \"LASTNAME\", \"GDEKT\"]].head(10).to_csv(\"nachnamen_small.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0c677-6b73-4d60-a8b8-88e235564698",
   "metadata": {},
   "source": [
    "By the way, if individual lines of code get a bit long and are no longer clear, you can put them in brackets and then insert line breaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e854d-7592-4758-8264-15bc5622b038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    nachnamen[[\"TIME_PERIOD\", \"LASTNAME\", \"GDEKT\"]]\n",
    "    .head(10)\n",
    "    .to_csv(\"nachnamen_small.csv\", index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1122cd1-97cd-49f1-b68b-70c0bcbabeae",
   "metadata": {},
   "source": [
    "## Loop in dataframes\n",
    "\n",
    "Looping through the rows of a df is a bit special. With `iterrows()` we get two outputs, the row index (`idx`) on the one hand and the current row as a list (`row`) on the other.\n",
    "\n",
    "Ah, and by the way, we use `If-Else` here to read only the first rows. We could perhaps do this more simply (e.g. `head(10)` for the dataframe), but this way you have also seen how to interrupt a loop using `break`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834e68f-3b0b-4414-95ac-5196cd41bff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in nachnamen.iterrows():\n",
    "    if index<10:\n",
    "        print(row['TIME_PERIOD'], row['LASTNAME'])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583230f4-4c97-4819-8be6-ff6c04b0387e",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "A typical first step to clean the data is filtering.\n",
    "\n",
    "### Filtering by a single value\n",
    "\n",
    "We pass a series of booleans to the dataframe. Wherever the canton is *ZH*, the booleans are `True`. Consequently, only the *ZH* rows are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4799f-77e5-44f5-aab2-91137bfdbe83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen_zh = nachnamen[nachnamen[\"GDEKT\"] == \"ZH\"]\n",
    "\n",
    "display(nachnamen_zh.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38a9af-1c28-44a2-8924-a92d70f0dc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen_haeufig = nachnamen[nachnamen[\"VALUE\"] > 5000]\n",
    "\n",
    "display(nachnamen_haeufig.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded9294-e82c-486e-ba6d-c90653a73820",
   "metadata": {},
   "source": [
    "### Filter by multiple values in the same column\n",
    "\n",
    "The `isin()` function allows us to pass a list of possible canton abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8088ed-6f8b-43c3-8bdb-a3f1ff80245a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen_zh_ag = nachnamen[nachnamen[\"GDEKT\"].isin([\"ZH\", \"AG\"])]\n",
    "\n",
    "display(nachnamen_zh_ag.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82393594-ee5f-411d-b495-1e5d6978603a",
   "metadata": {},
   "source": [
    "### Filter by multiple values in different columns\n",
    "\n",
    "- Multiple statements must be wrapped individually in brackets\n",
    "- The vertical bar (`|`) means *or* to make an *and* intersection between two statements you can use `&`\n",
    "- Here we use a function from the `str` class as the second statement, namely `startswith()`, to obtain only surnames beginning with *M*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30fcec-03f9-4454-84f9-1d2b936e738c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen_haeufig = nachnamen[(nachnamen[\"VALUE\"] > 5000) | (nachnamen[\"LASTNAME\"].str.startswith(\"M\"))]\n",
    "\n",
    "display(nachnamen_haeufig.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46b441",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Another typical task: Search, remove, repalce missing data.\n",
    "\n",
    "First we need some data with missing information (`None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750cc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'A': [1, 2, None, 4, None], \n",
    "        'B': [None, 2, 3, 4, None]\n",
    "        }\n",
    "\n",
    "missing = pd.DataFrame(data)\n",
    "\n",
    "display(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140c10d",
   "metadata": {},
   "source": [
    "Count missing data per column (`axis=1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06560eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f611ad",
   "metadata": {},
   "source": [
    "Filter rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc919a5f",
   "metadata": {},
   "source": [
    "Filter rows where a specific column has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da33af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing[missing['A'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b06a4d",
   "metadata": {},
   "source": [
    "Remove rows where all elements are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73004d7c",
   "metadata": {},
   "source": [
    "Replace NaN with a specific value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d834d",
   "metadata": {},
   "source": [
    "Replace NaN in a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing['A'].fillna(value=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec01db0f",
   "metadata": {},
   "source": [
    "Replace NaN using forward fill (propagate last valid value forward). There is also a backward-fill: `bfill()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac62e1-4b37-4b2c-a945-ad1aff39913f",
   "metadata": {},
   "source": [
    "## Aggregate data frames\n",
    "\n",
    "Aggregating information is a fundamental task when processing and analyzing data. Here I show just a few examples. The topic is almost endless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9313d0-e071-4b17-9c93-582743081175",
   "metadata": {},
   "source": [
    "### Counting\n",
    "\n",
    "How many rows does the DF have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad1239-6388-4f07-ae30-f236776ccc3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape = nachnamen.shape\n",
    "length = len(nachnamen)\n",
    "\n",
    "print(f\"Der Dataframe hat {shape[0]} (oder {length}) Zeilen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85669f93-663f-49ec-9661-4f975faa45f0",
   "metadata": {},
   "source": [
    "### Sum\n",
    "\n",
    "What is the sum of all surname frequencies? (shouldn't that roughly correspond to the population of Switzerland?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe14597-df60-42d1-abdb-fb123d51b58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen[\"VALUE\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8f333-aba9-48a7-acb7-d0ff615f2341",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "Grouping or `groupBy` is a comprehensive topic. We are just touching on it here. If you would like to know more, you can find out more [here](https://realpython.com/pandas-groupby/).\n",
    "\n",
    "- We group by last name: `groupby(['LASTNAME'])`\n",
    "- Then we aggregate: \n",
    "    - Frequency of each surname (sum of canton frequencies): `lastname_sum=('VALUE', 'sum')`\n",
    "    - Lowest canton frequencies: `lastname_min=('VALUE', 'min')`\n",
    "    - Number of cantons in which each surname occurs: `lastname_n_cantons=('GDEKT', 'nunique')`\n",
    "- Then we sort the whole thing so that the most frequent surnames come first (`sort_values(“lastname_sum”, ascending=False)`) and we reset the index (for whatever reason!?)\n",
    "\n",
    "There are different `groupBy` syntaxes. I particularly like this one (see especially `agg()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5566cb-3c90-4377-ad4d-005c6ff0feb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen_grp = (\n",
    "    nachnamen\n",
    "    .groupby(['LASTNAME'])\n",
    "    .agg(\n",
    "        lastname_sum=('VALUE', 'sum'),\n",
    "        lastname_min=('VALUE', 'min'),\n",
    "        lastname_n_kantone=('GDEKT', 'nunique')\n",
    "    )\n",
    "    .sort_values(\"lastname_sum\", ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "nachnamen_grp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97d500-119f-48c5-8f27-66a67fe7eff1",
   "metadata": {},
   "source": [
    "### Remove duplicates\n",
    "\n",
    "We often find duplicates in the data. If you want to remove duplicates that affect all columns (real duplicates), the following will help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7efce9-0e5f-4338-b051-3b38d2ddc7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14811ada-afbb-4b55-a9d9-950cea193e81",
   "metadata": {},
   "source": [
    "If duplicates are to be removed in relation to individual columns only, you can use the `subset` parameter. `keep=“first”` means that the first column is kept for each series of duplicates. You can check which is the first column by prefixing it with `sort`.\n",
    "\n",
    "Here, for example, we only keep the most frequent surname per canton per year (remove canton duplicates but sort by frequency first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca548a3-aad5-4989-8fb0-61c852e85427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen_haeufigst = (nachnamen\n",
    "                    .sort_values(by='VALUE', ascending=False) # ascending=False heisst absteigend\n",
    "                    .drop_duplicates(subset=['GDEKT', 'TIME_PERIOD'], keep='first')\n",
    "                    )\n",
    "\n",
    "nachnamen_haeufigst.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e247ee-389a-43e4-96ce-dc77b7222fb6",
   "metadata": {},
   "source": [
    "### Long2Wide and Wide2Long Transformations\n",
    "\n",
    "Moving information from columns to rows or from rows to columns, is certainly not the first thing that comes to mind. \n",
    "Unfortunately, it happens quite often in programming. Statistical models, for example, like to store information in columns (i.e. each row is a unique sample), while visualization is easier if the information is stored in rows.\n",
    "\n",
    "We make up some data to demonstrate Long2Wide first, using `pivot()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f463921",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Date': ['2024-11-01', '2024-11-01', '2024-11-02', '2024-11-02', '2024-11-03'],\n",
    "    'Product': ['A', 'B', 'A', 'B', 'A'],\n",
    "    'Sales': [100, 150, 200, 250, 300]\n",
    "}\n",
    "prod = pd.DataFrame(data)\n",
    "\n",
    "display(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a2f25",
   "metadata": {},
   "source": [
    "We would like to have a table where the Date is in the rows (`index`) and the two Products are in two seperate columns (`columns`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881533eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_w = prod.pivot(index=['Date'], columns='Product', values='Sales').reset_index()\n",
    "\n",
    "display(prod_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b73653-253c-42db-b0eb-c7b3dfc54a7a",
   "metadata": {},
   "source": [
    "We can undo this, i.e. Wide2Long transformatino, with `melt()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca892ac-131e-4e35-b43f-99a2d97a831e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prod_l = (\n",
    "    pd.melt(\n",
    "        prod_w, \n",
    "        id_vars=[\"Date\"], \n",
    "        var_name='Product', \n",
    "        value_name='Sales')\n",
    ")\n",
    "\n",
    "display(prod_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e8535d-6a20-4e7f-8699-09acb5348a21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Working with date & time\n",
    "\n",
    "Working with date and time fields is somewhat annoying. We use the manually created table with the three birthdays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a534b-b439-44f8-9445-4ba82884eeb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(fam.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d56de-ca4a-4ebb-8a4c-a8a70ace44d4",
   "metadata": {},
   "source": [
    "You can see that birthday has been saved as *object* (actually *str*). To be able to work with it, we need to reformat the birthday column into a date format. For this we use the Pandas function `pd.to_datetime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb945ce-5fa7-4d1f-af5d-ce1d362e6e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam[\"geburtstag\"] = pd.to_datetime(fam[\"geburtstag\"])\n",
    "\n",
    "print(fam.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42944ea8-9df1-49bd-9f50-452633fba88d",
   "metadata": {},
   "source": [
    "Now we can calculate with the date. For example, we can calculate how much older Othmar is than Oskar (we do this with `iloc[]`, which is always a bit confusing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9b609-2338-491f-8f20-b17ec1718202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = fam.iloc[2, 2] - fam.iloc[1, 2]\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7e56a-f26d-4eab-8be5-6f1c4879795e",
   "metadata": {},
   "source": [
    "The difference between two date fields is returned in `Timedelta()` format. This in turn can be converted into a more common format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ac025-e9c3-4b11-b3f9-96f116a5b3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54733a8a-c7ba-469d-bbef-8c642b19491b",
   "metadata": {},
   "source": [
    "## Combine dataframes\n",
    "\n",
    "Finally to Pandas, but very important, the merging of different tables. \n",
    "\n",
    "### Join\n",
    "For our example, we can consider, for example, specifying the frequency of surnames as percentages of the total population of the cantons instead of absolute numbers.\n",
    "\n",
    "To do this, we need a second table with the resident population per canton. We could download this from OpenData.ch and import it. As there are only a few rows, I create the table manually.\n",
    "\n",
    "The information on the population of the canton must now be added to each line of the surname table. This is usually called a *join*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25945930-8962-4ced-a318-7f715e742d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Kanton': ['ZH', 'BE', 'LU', 'UR', 'SZ', 'OW', 'NW', 'GL', 'ZG', \n",
    "                     'FR', 'SO', 'BS', 'BL', 'SH', 'AR', 'AI', 'SG', 'GR', \n",
    "                     'AG', 'TG', 'TI', 'VD', 'VS', 'NE', 'GE', 'JU'],\n",
    "    'Bevoelkerung': [1538565, 1034977, 416347, 36707, 160480, 38576, 43160, 40653, 127387,\n",
    "                   325822, 275596, 201971, 289534, 83041, 55630, 16145, 510734, 200288, \n",
    "                   700466, 282909, 353343, 814762, 345504, 176850, 504128, 73419]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "bev_kanton = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd61c4f-a716-4494-99fe-b43b7c54d8a6",
   "metadata": {},
   "source": [
    "- We take the table with the surnames (*left*) and add the population per canton (*right*)\n",
    "- We use the `merge()` function (there would also be a `join()` function)\n",
    "- In the surnames we have the column `GDEKT`, which matches the column `canton` in the population table: `left_on='GDEKT', right_on='Kanton'`\n",
    "- We select an `inner` join. We only keep the rows that are contained in both tables (for example, if a canton in the name table does not appear in the population table, it is not included in the join).\n",
    "\n",
    "A more comprehensive discussion of joins can be found [here](https://pandas.pydata.org/docs/user_guide/merging.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4800e3-2a46-440a-bf30-61f8f2bccd38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen_bev = pd.merge(nachnamen, bev_kanton, left_on='GDEKT', right_on='Kanton', how='inner')\n",
    "\n",
    "display(nachnamen_bev.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619ed9d-0dad-4510-b4e9-412b6f716318",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we just need to calculate the percentages in a new field. Optionally, we can sort the dataframe to see which surnames are the most common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e99de-d257-4548-b95a-8cec8ff1f1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nachnamen_bev[\"VALUE_REL\"] = nachnamen_bev[\"VALUE\"] / nachnamen_bev[\"Bevoelkerung\"]\n",
    "\n",
    "nachnamen_bev.sort_values(\"VALUE_REL\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec54aa-7e0e-4232-8066-8b76c834c7a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ah, a typical *small data problem*. Surnames in small cantons are, relatively speaking, the ones with the broadest distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698a5af-f529-4a43-81a2-50764711f14e",
   "metadata": {},
   "source": [
    "### Concatenate\n",
    "\n",
    "A common form of merging data frames is the combination of two data sets with the same or similar information. Rows are added rather than columns as in a *join*. This is called *concatenate* (or *union*).\n",
    "\n",
    "Here we take the table with the family members and combine it with a new, second table containing a few more people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548d20f-7a6e-4a9d-83a3-c3135ac713ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\"name\": [\"Obama\", \"Taylor\"], \"groesse\": [187.5, 178.1], \"beruehmt\": [True, True]}\n",
    "\n",
    "#Dictionary to Pandas\n",
    "fam_zusatz = pd.DataFrame(data=data)\n",
    "\n",
    "display(fam_zusatz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76675004-2df1-4f37-a3d4-fd85700b627b",
   "metadata": {},
   "source": [
    "The new table does not contain all the columns of the family table (*birthday*), but has an additional column (*birthday*). The columns are also arranged differently. However, this does not matter for the *concatenate*.\n",
    "\n",
    "- We use the `concat()` function of Pandas\n",
    "- The columns are automatically arranged 'correctly' and missing information is added with `NaN` (*Not a Number*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b2a89-b19f-40d6-b265-5f2e672b871f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam_gross = pd.concat([fam, fam_zusatz], ignore_index=True)\n",
    "\n",
    "display(fam_gross)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
